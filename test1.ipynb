{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load the model is: 0.6331794261932373\n",
      "Time taken for model inference is: 0.8181626796722412\n",
      "model runs at 1.22 FPS\n",
      "Time taken for model inference is: 0.9381959438323975\n",
      "model runs at 2.13 FPS\n",
      "Time taken for model inference is: 1.07114839553833\n",
      "model runs at 2.8 FPS\n",
      "Time taken for model inference is: 1.215595006942749\n",
      "model runs at 3.29 FPS\n",
      "Time taken for model inference is: 1.333489179611206\n",
      "model runs at 3.75 FPS\n",
      "Time taken for model inference is: 1.3996005058288574\n",
      "model runs at 4.29 FPS\n",
      "Time taken for model inference is: 1.5107731819152832\n",
      "model runs at 4.63 FPS\n",
      "Time taken for model inference is: 1.6209633350372314\n",
      "model runs at 4.94 FPS\n",
      "Time taken for model inference is: 1.709618091583252\n",
      "model runs at 5.26 FPS\n",
      "Time taken for model inference is: 1.8709006309509277\n",
      "model runs at 5.34 FPS\n",
      "Time taken for model inference is: 1.9670381546020508\n",
      "model runs at 5.59 FPS\n",
      "Time taken for model inference is: 2.0627331733703613\n",
      "model runs at 5.82 FPS\n",
      "Time taken for model inference is: 2.175286054611206\n",
      "model runs at 5.97 FPS\n",
      "Time taken for model inference is: 2.330556631088257\n",
      "model runs at 6.01 FPS\n",
      "Time taken for model inference is: 2.487684965133667\n",
      "model runs at 6.03 FPS\n",
      "Time taken for model inference is: 2.592541217803955\n",
      "model runs at 6.17 FPS\n",
      "Time taken for model inference is: 2.680898666381836\n",
      "model runs at 6.34 FPS\n",
      "Time taken for model inference is: 2.788249969482422\n",
      "model runs at 6.46 FPS\n",
      "Time taken for model inference is: 2.882749080657959\n",
      "model runs at 6.59 FPS\n",
      "Time taken for model inference is: 2.966310977935791\n",
      "model runs at 6.74 FPS\n",
      "Time taken for model inference is: 3.06018328666687\n",
      "model runs at 6.86 FPS\n",
      "Time taken for model inference is: 3.1469228267669678\n",
      "model runs at 6.99 FPS\n",
      "Time taken for model inference is: 3.242591142654419\n",
      "model runs at 7.09 FPS\n",
      "Time taken for model inference is: 3.332589864730835\n",
      "model runs at 7.2 FPS\n",
      "Time taken for model inference is: 3.4343173503875732\n",
      "model runs at 7.28 FPS\n",
      "Time taken for model inference is: 3.5161943435668945\n",
      "model runs at 7.39 FPS\n",
      "Time taken for model inference is: 3.616952896118164\n",
      "model runs at 7.46 FPS\n",
      "Time taken for model inference is: 3.728715419769287\n",
      "model runs at 7.51 FPS\n",
      "Time taken for model inference is: 3.8385844230651855\n",
      "model runs at 7.55 FPS\n",
      "Time taken for model inference is: 3.9538917541503906\n",
      "model runs at 7.59 FPS\n",
      "Time taken for model inference is: 4.059749364852905\n",
      "model runs at 7.63 FPS\n",
      "Time taken for model inference is: 4.186125993728638\n",
      "model runs at 7.64 FPS\n",
      "Time taken for model inference is: 4.2690770626068115\n",
      "model runs at 7.73 FPS\n",
      "Time taken for model inference is: 4.376422882080078\n",
      "model runs at 7.77 FPS\n",
      "Time taken for model inference is: 4.483073711395264\n",
      "model runs at 7.81 FPS\n",
      "Time taken for model inference is: 4.586557388305664\n",
      "model runs at 7.85 FPS\n",
      "Time taken for model inference is: 4.6756508350372314\n",
      "model runs at 7.91 FPS\n",
      "Time taken for model inference is: 4.809068441390991\n",
      "model runs at 7.9 FPS\n",
      "Time taken for model inference is: 4.906046152114868\n",
      "model runs at 7.95 FPS\n",
      "Time taken for model inference is: 4.997403383255005\n",
      "model runs at 8.0 FPS\n",
      "Time taken for model inference is: 5.1360814571380615\n",
      "model runs at 7.98 FPS\n",
      "Time taken for model inference is: 5.233858108520508\n",
      "model runs at 8.02 FPS\n",
      "Time taken for model inference is: 5.306098937988281\n",
      "model runs at 8.1 FPS\n",
      "Time taken for model inference is: 5.393121004104614\n",
      "model runs at 8.16 FPS\n",
      "Time taken for model inference is: 5.490044593811035\n",
      "model runs at 8.2 FPS\n",
      "Time taken for model inference is: 5.579420804977417\n",
      "model runs at 8.24 FPS\n",
      "Time taken for model inference is: 5.6874308586120605\n",
      "model runs at 8.26 FPS\n",
      "Time taken for model inference is: 5.782283544540405\n",
      "model runs at 8.3 FPS\n",
      "Time taken for model inference is: 5.874022722244263\n",
      "model runs at 8.34 FPS\n",
      "Time taken for model inference is: 5.953144311904907\n",
      "model runs at 8.4 FPS\n",
      "Time taken for model inference is: 6.047864198684692\n",
      "model runs at 8.43 FPS\n",
      "Time taken for model inference is: 6.136270761489868\n",
      "model runs at 8.47 FPS\n",
      "Time taken for model inference is: 6.233764886856079\n",
      "model runs at 8.5 FPS\n",
      "Time taken for model inference is: 6.329927206039429\n",
      "model runs at 8.53 FPS\n",
      "Time taken for model inference is: 6.409635782241821\n",
      "model runs at 8.58 FPS\n",
      "Time taken for model inference is: 6.489424467086792\n",
      "model runs at 8.63 FPS\n",
      "Time taken for model inference is: 6.581393718719482\n",
      "model runs at 8.66 FPS\n",
      "Time taken for model inference is: 6.666251182556152\n",
      "model runs at 8.7 FPS\n",
      "Time taken for model inference is: 6.752165794372559\n",
      "model runs at 8.74 FPS\n",
      "Time taken for model inference is: 6.841910123825073\n",
      "model runs at 8.77 FPS\n",
      "Time taken for model inference is: 6.921672582626343\n",
      "model runs at 8.81 FPS\n",
      "Time taken for model inference is: 7.005826711654663\n",
      "model runs at 8.85 FPS\n",
      "Time taken for model inference is: 7.104047536849976\n",
      "model runs at 8.87 FPS\n",
      "Time taken for model inference is: 7.199045896530151\n",
      "model runs at 8.89 FPS\n",
      "Time taken for model inference is: 7.290028095245361\n",
      "model runs at 8.92 FPS\n",
      "Time taken for model inference is: 7.370994806289673\n",
      "model runs at 8.95 FPS\n",
      "Time taken for model inference is: 7.450611114501953\n",
      "model runs at 8.99 FPS\n",
      "Time taken for model inference is: 7.555617570877075\n",
      "model runs at 9.0 FPS\n",
      "Time taken for model inference is: 7.651515960693359\n",
      "model runs at 9.02 FPS\n",
      "Time taken for model inference is: 7.743910074234009\n",
      "model runs at 9.04 FPS\n",
      "Time taken for model inference is: 7.831405878067017\n",
      "model runs at 9.06 FPS\n",
      "Time taken for model inference is: 7.931846618652344\n",
      "model runs at 9.08 FPS\n",
      "Time taken for model inference is: 8.019879817962646\n",
      "model runs at 9.1 FPS\n",
      "Time taken for model inference is: 8.103358507156372\n",
      "model runs at 9.13 FPS\n",
      "Time taken for model inference is: 8.196709394454956\n",
      "model runs at 9.15 FPS\n",
      "Time taken for model inference is: 8.275546789169312\n",
      "model runs at 9.18 FPS\n",
      "Time taken for model inference is: 8.3667631149292\n",
      "model runs at 9.2 FPS\n",
      "Time taken for model inference is: 8.465230226516724\n",
      "model runs at 9.21 FPS\n",
      "Time taken for model inference is: 8.550832748413086\n",
      "model runs at 9.24 FPS\n",
      "Time taken for model inference is: 8.654946088790894\n",
      "model runs at 9.24 FPS\n",
      "Time taken for model inference is: 8.73717474937439\n",
      "model runs at 9.27 FPS\n",
      "Time taken for model inference is: 8.820222616195679\n",
      "model runs at 9.3 FPS\n",
      "Time taken for model inference is: 8.912662744522095\n",
      "model runs at 9.31 FPS\n",
      "Time taken for model inference is: 9.013587474822998\n",
      "model runs at 9.32 FPS\n",
      "Time taken for model inference is: 9.090811729431152\n",
      "model runs at 9.35 FPS\n",
      "Time taken for model inference is: 9.181557655334473\n",
      "model runs at 9.37 FPS\n",
      "Time taken for model inference is: 9.279351234436035\n",
      "model runs at 9.38 FPS\n",
      "Time taken for model inference is: 9.371281862258911\n",
      "model runs at 9.39 FPS\n",
      "Time taken for model inference is: 9.471956491470337\n",
      "model runs at 9.4 FPS\n",
      "Time taken for model inference is: 9.560098886489868\n",
      "model runs at 9.41 FPS\n",
      "Time taken for model inference is: 9.646732330322266\n",
      "model runs at 9.43 FPS\n",
      "Time taken for model inference is: 9.735416889190674\n",
      "model runs at 9.45 FPS\n",
      "Time taken for model inference is: 9.82954216003418\n",
      "model runs at 9.46 FPS\n",
      "Time taken for model inference is: 9.911265134811401\n",
      "model runs at 9.48 FPS\n",
      "Time taken for model inference is: 10.009191274642944\n",
      "model runs at 9.49 FPS\n",
      "Time taken for model inference is: 10.112605094909668\n",
      "model runs at 9.49 FPS\n",
      "Time taken for model inference is: 10.212173223495483\n",
      "model runs at 9.5 FPS\n",
      "Time taken for model inference is: 10.327507019042969\n",
      "model runs at 9.49 FPS\n",
      "Time taken for model inference is: 10.411169052124023\n",
      "model runs at 9.51 FPS\n",
      "Time taken for model inference is: 10.510571956634521\n",
      "model runs at 9.51 FPS\n",
      "Time taken for model inference is: 10.600501775741577\n",
      "model runs at 9.53 FPS\n",
      "Time taken for model inference is: 10.682302236557007\n",
      "model runs at 9.55 FPS\n",
      "Time taken for model inference is: 10.77052354812622\n",
      "model runs at 9.56 FPS\n",
      "Time taken for model inference is: 10.863551378250122\n",
      "model runs at 9.57 FPS\n",
      "Time taken for model inference is: 10.939940690994263\n",
      "model runs at 9.6 FPS\n",
      "Time taken for model inference is: 11.025670766830444\n",
      "model runs at 9.61 FPS\n",
      "Time taken for model inference is: 11.11927580833435\n",
      "model runs at 9.62 FPS\n",
      "Time taken for model inference is: 11.202934980392456\n",
      "model runs at 9.64 FPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for model inference is: 11.294758796691895\n",
      "model runs at 9.65 FPS\n",
      "Time taken for model inference is: 11.390020608901978\n",
      "model runs at 9.66 FPS\n",
      "Time taken for model inference is: 11.469610214233398\n",
      "model runs at 9.68 FPS\n",
      "Time taken for model inference is: 11.559155225753784\n",
      "model runs at 9.69 FPS\n",
      "Time taken for model inference is: 11.656436920166016\n",
      "model runs at 9.69 FPS\n",
      "Time taken for model inference is: 11.738303422927856\n",
      "model runs at 9.71 FPS\n",
      "Time taken for model inference is: 11.830761671066284\n",
      "model runs at 9.72 FPS\n",
      "Time taken for model inference is: 11.925647497177124\n",
      "model runs at 9.73 FPS\n",
      "Time taken for model inference is: 12.010608196258545\n",
      "model runs at 9.74 FPS\n",
      "Time taken for model inference is: 12.095542192459106\n",
      "model runs at 9.76 FPS\n",
      "Time taken for model inference is: 12.194018840789795\n",
      "model runs at 9.76 FPS\n",
      "Time taken for model inference is: 12.275289058685303\n",
      "model runs at 9.78 FPS\n",
      "Time taken for model inference is: 12.352518558502197\n",
      "model runs at 9.8 FPS\n",
      "Time taken for model inference is: 12.442689418792725\n",
      "model runs at 9.8 FPS\n",
      "Time taken for model inference is: 12.531460523605347\n",
      "model runs at 9.81 FPS\n",
      "Time taken for model inference is: 12.624175310134888\n",
      "model runs at 9.82 FPS\n",
      "Time taken for model inference is: 12.713635206222534\n",
      "model runs at 9.83 FPS\n",
      "Time taken for model inference is: 12.795711755752563\n",
      "model runs at 9.85 FPS\n",
      "Time taken for model inference is: 12.882568836212158\n",
      "model runs at 9.86 FPS\n",
      "Time taken for model inference is: 12.973371982574463\n",
      "model runs at 9.87 FPS\n",
      "Time taken for model inference is: 13.051948308944702\n",
      "model runs at 9.88 FPS\n",
      "Time taken for model inference is: 13.140674829483032\n",
      "model runs at 9.89 FPS\n",
      "Time taken for model inference is: 13.235474348068237\n",
      "model runs at 9.9 FPS\n",
      "Time taken for model inference is: 13.313356399536133\n",
      "model runs at 9.91 FPS\n",
      "Time taken for model inference is: 13.40793490409851\n",
      "model runs at 9.92 FPS\n",
      "Time taken for model inference is: 13.504231214523315\n",
      "model runs at 9.92 FPS\n",
      "Time taken for model inference is: 13.581224918365479\n",
      "model runs at 9.94 FPS\n",
      "Time taken for model inference is: 13.667441368103027\n",
      "model runs at 9.95 FPS\n",
      "Time taken for model inference is: 13.761147260665894\n",
      "model runs at 9.96 FPS\n",
      "Time taken for model inference is: 13.850369691848755\n",
      "model runs at 9.96 FPS\n",
      "Time taken for model inference is: 13.941785097122192\n",
      "model runs at 9.97 FPS\n",
      "Time taken for model inference is: 14.034508228302002\n",
      "model runs at 9.98 FPS\n",
      "Time taken for model inference is: 14.115175247192383\n",
      "model runs at 9.99 FPS\n",
      "Time taken for model inference is: 14.201544523239136\n",
      "model runs at 10.0 FPS\n",
      "Time taken for model inference is: 14.29145336151123\n",
      "model runs at 10.01 FPS\n",
      "Time taken for model inference is: 14.371906518936157\n",
      "model runs at 10.02 FPS\n",
      "Time taken for model inference is: 14.464537858963013\n",
      "model runs at 10.02 FPS\n",
      "Time taken for model inference is: 14.55604600906372\n",
      "model runs at 10.03 FPS\n",
      "Time taken for model inference is: 14.64296555519104\n",
      "model runs at 10.04 FPS\n",
      "Time taken for model inference is: 14.739848136901855\n",
      "model runs at 10.04 FPS\n",
      "Time taken for model inference is: 14.829870223999023\n",
      "model runs at 10.05 FPS\n",
      "Time taken for model inference is: 14.907022953033447\n",
      "model runs at 10.06 FPS\n",
      "Time taken for model inference is: 14.995052576065063\n",
      "model runs at 10.07 FPS\n",
      "Time taken for model inference is: 15.099282503128052\n",
      "model runs at 10.07 FPS\n",
      "Time taken for model inference is: 15.189473152160645\n",
      "model runs at 10.07 FPS\n",
      "Time taken for model inference is: 15.284226417541504\n",
      "model runs at 10.08 FPS\n",
      "Time taken for model inference is: 15.373003005981445\n",
      "model runs at 10.08 FPS\n",
      "Time taken for model inference is: 15.453794479370117\n",
      "model runs at 10.09 FPS\n",
      "Time taken for model inference is: 15.539409160614014\n",
      "model runs at 10.1 FPS\n",
      "Time taken for model inference is: 15.639302253723145\n",
      "model runs at 10.1 FPS\n",
      "Time taken for model inference is: 15.73146367073059\n",
      "model runs at 10.11 FPS\n",
      "Time taken for model inference is: 15.848660707473755\n",
      "model runs at 10.1 FPS\n",
      "Time taken for model inference is: 15.935224056243896\n",
      "model runs at 10.1 FPS\n",
      "Time taken for model inference is: 16.015352487564087\n",
      "model runs at 10.12 FPS\n",
      "Time taken for model inference is: 16.106255531311035\n",
      "model runs at 10.12 FPS\n",
      "Time taken for model inference is: 16.197828769683838\n",
      "model runs at 10.12 FPS\n",
      "Time taken for model inference is: 16.27792501449585\n",
      "model runs at 10.14 FPS\n",
      "Time taken for model inference is: 16.35728120803833\n",
      "model runs at 10.15 FPS\n",
      "Time taken for model inference is: 16.453972101211548\n",
      "model runs at 10.15 FPS\n",
      "Time taken for model inference is: 16.53169298171997\n",
      "model runs at 10.16 FPS\n",
      "Time taken for model inference is: 16.617323637008667\n",
      "model runs at 10.17 FPS\n",
      "Time taken for model inference is: 16.708300828933716\n",
      "model runs at 10.17 FPS\n",
      "Time taken for model inference is: 16.78844714164734\n",
      "model runs at 10.19 FPS\n",
      "Time taken for model inference is: 16.882401943206787\n",
      "model runs at 10.19 FPS\n",
      "Time taken for model inference is: 16.981780767440796\n",
      "model runs at 10.19 FPS\n",
      "Time taken for model inference is: 17.064669370651245\n",
      "model runs at 10.2 FPS\n",
      "Time taken for model inference is: 17.15600275993347\n",
      "model runs at 10.2 FPS\n",
      "Time taken for model inference is: 17.2456955909729\n",
      "model runs at 10.21 FPS\n",
      "Time taken for model inference is: 17.320770025253296\n",
      "model runs at 10.22 FPS\n",
      "Time taken for model inference is: 17.40140700340271\n",
      "model runs at 10.23 FPS\n",
      "Time taken for model inference is: 17.483837604522705\n",
      "model runs at 10.24 FPS\n",
      "Time taken for model inference is: 17.56546950340271\n",
      "model runs at 10.25 FPS\n",
      "Time taken for model inference is: 17.65128493309021\n",
      "model runs at 10.25 FPS\n",
      "Time taken for model inference is: 17.761397123336792\n",
      "model runs at 10.25 FPS\n",
      "Time taken for model inference is: 17.85146188735962\n",
      "model runs at 10.25 FPS\n",
      "Time taken for model inference is: 17.953605890274048\n",
      "model runs at 10.25 FPS\n",
      "Time taken for model inference is: 18.03544569015503\n",
      "model runs at 10.26 FPS\n",
      "Time taken for model inference is: 18.11536407470703\n",
      "model runs at 10.27 FPS\n",
      "Time taken for model inference is: 18.21737289428711\n",
      "model runs at 10.26 FPS\n",
      "Time taken for model inference is: 18.328800916671753\n",
      "model runs at 10.26 FPS\n",
      "Time taken for model inference is: 18.40910577774048\n",
      "model runs at 10.27 FPS\n",
      "Time taken for model inference is: 18.509589672088623\n",
      "model runs at 10.26 FPS\n",
      "Time taken for model inference is: 18.606934547424316\n",
      "model runs at 10.26 FPS\n",
      "Time taken for model inference is: 18.69095754623413\n",
      "model runs at 10.27 FPS\n",
      "Time taken for model inference is: 18.787869215011597\n",
      "model runs at 10.27 FPS\n",
      "Time taken for model inference is: 18.926641941070557\n",
      "model runs at 10.25 FPS\n",
      "Time taken for model inference is: 19.06974458694458\n",
      "model runs at 10.23 FPS\n",
      "Time taken for model inference is: 19.229634284973145\n",
      "model runs at 10.19 FPS\n",
      "Time taken for model inference is: 19.412039756774902\n",
      "model runs at 10.15 FPS\n",
      "Time taken for model inference is: 19.511346101760864\n",
      "model runs at 10.15 FPS\n",
      "Time taken for model inference is: 19.600616931915283\n",
      "model runs at 10.15 FPS\n",
      "Time taken for model inference is: 19.689025402069092\n",
      "model runs at 10.16 FPS\n",
      "Time taken for model inference is: 19.786440134048462\n",
      "model runs at 10.16 FPS\n",
      "Time taken for model inference is: 19.885621786117554\n",
      "model runs at 10.16 FPS\n",
      "Time taken for model inference is: 19.969254732131958\n",
      "model runs at 10.17 FPS\n",
      "Time taken for model inference is: 20.05730938911438\n",
      "model runs at 10.17 FPS\n",
      "Time taken for model inference is: 20.1687593460083\n",
      "model runs at 10.16 FPS\n",
      "Time taken for model inference is: 20.258111476898193\n",
      "model runs at 10.17 FPS\n",
      "Time taken for model inference is: 20.378097534179688\n",
      "model runs at 10.16 FPS\n",
      "Time taken for model inference is: 20.459314107894897\n",
      "model runs at 10.17 FPS\n",
      "Time taken for model inference is: 20.542887449264526\n",
      "model runs at 10.17 FPS\n",
      "Time taken for model inference is: 20.634729385375977\n",
      "model runs at 10.18 FPS\n",
      "Time taken for model inference is: 20.728102922439575\n",
      "model runs at 10.18 FPS\n",
      "Time taken for model inference is: 20.80839991569519\n",
      "model runs at 10.19 FPS\n",
      "Time taken for model inference is: 20.90672278404236\n",
      "model runs at 10.19 FPS\n",
      "Time taken for model inference is: 21.005451440811157\n",
      "model runs at 10.19 FPS\n",
      "Time taken for model inference is: 21.08854341506958\n",
      "model runs at 10.2 FPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for model inference is: 21.19007706642151\n",
      "model runs at 10.19 FPS\n",
      "Time taken for model inference is: 21.286808013916016\n",
      "model runs at 10.19 FPS\n",
      "Time taken for model inference is: 21.36752414703369\n",
      "model runs at 10.2 FPS\n",
      "Time taken for model inference is: 21.463810443878174\n",
      "model runs at 10.2 FPS\n",
      "Time taken for model inference is: 21.55496048927307\n",
      "model runs at 10.21 FPS\n",
      "Time taken for model inference is: 21.63706398010254\n",
      "model runs at 10.21 FPS\n",
      "Time taken for model inference is: 21.72509479522705\n",
      "model runs at 10.22 FPS\n",
      "Time taken for model inference is: 21.81651210784912\n",
      "model runs at 10.22 FPS\n",
      "Time taken for model inference is: 21.897637844085693\n",
      "model runs at 10.23 FPS\n",
      "Time taken for model inference is: 21.98367691040039\n",
      "model runs at 10.23 FPS\n",
      "Time taken for model inference is: 22.08981704711914\n",
      "model runs at 10.23 FPS\n",
      "Time taken for model inference is: 22.171278953552246\n",
      "model runs at 10.24 FPS\n",
      "Time taken for model inference is: 22.266630172729492\n",
      "model runs at 10.24 FPS\n",
      "Time taken for model inference is: 22.354744911193848\n",
      "model runs at 10.24 FPS\n",
      "Time taken for model inference is: 22.433987140655518\n",
      "model runs at 10.25 FPS\n",
      "Time taken for model inference is: 22.518828868865967\n",
      "model runs at 10.26 FPS\n",
      "Time taken for model inference is: 22.618531703948975\n",
      "model runs at 10.26 FPS\n",
      "Time taken for model inference is: 22.705570697784424\n",
      "model runs at 10.26 FPS\n",
      "Time taken for model inference is: 22.799463987350464\n",
      "model runs at 10.26 FPS\n",
      "Time taken for model inference is: 22.90189290046692\n",
      "model runs at 10.26 FPS\n",
      "Time taken for model inference is: 22.9837863445282\n",
      "model runs at 10.27 FPS\n",
      "Time taken for model inference is: 23.067736625671387\n",
      "model runs at 10.27 FPS\n",
      "Time taken for model inference is: 23.156810760498047\n",
      "model runs at 10.28 FPS\n",
      "Time taken for model inference is: 23.233850955963135\n",
      "model runs at 10.29 FPS\n",
      "Time taken for model inference is: 23.31830668449402\n",
      "model runs at 10.29 FPS\n",
      "Time taken for model inference is: 23.41003394126892\n",
      "model runs at 10.29 FPS\n",
      "Time taken for model inference is: 23.497674703598022\n",
      "model runs at 10.3 FPS\n",
      "Time taken for model inference is: 23.59198307991028\n",
      "model runs at 10.3 FPS\n",
      "Time taken for model inference is: 23.685326099395752\n",
      "model runs at 10.3 FPS\n",
      "Time taken for model inference is: 23.76615619659424\n",
      "model runs at 10.31 FPS\n",
      "Time taken for model inference is: 23.852510452270508\n",
      "model runs at 10.31 FPS\n",
      "Time taken for model inference is: 23.946551084518433\n",
      "model runs at 10.31 FPS\n",
      "Time taken for model inference is: 24.02506709098816\n",
      "model runs at 10.32 FPS\n",
      "Time taken for model inference is: 24.10549569129944\n",
      "model runs at 10.33 FPS\n",
      "Time taken for model inference is: 24.21420931816101\n",
      "model runs at 10.32 FPS\n",
      "Time taken for model inference is: 24.299696445465088\n",
      "model runs at 10.33 FPS\n",
      "Time taken for model inference is: 24.390923500061035\n",
      "model runs at 10.33 FPS\n",
      "Time taken for model inference is: 24.481945276260376\n",
      "model runs at 10.33 FPS\n",
      "Time taken for model inference is: 24.576922178268433\n",
      "model runs at 10.33 FPS\n",
      "Time taken for model inference is: 24.667081594467163\n",
      "model runs at 10.34 FPS\n",
      "Time taken for model inference is: 24.752233743667603\n",
      "model runs at 10.34 FPS\n",
      "Time taken for model inference is: 24.850630283355713\n",
      "model runs at 10.34 FPS\n",
      "Time taken for model inference is: 24.928019523620605\n",
      "model runs at 10.35 FPS\n",
      "Time taken for model inference is: 25.014143228530884\n",
      "model runs at 10.35 FPS\n",
      "Time taken for model inference is: 25.10818386077881\n",
      "model runs at 10.36 FPS\n",
      "Time taken for model inference is: 25.19159436225891\n",
      "model runs at 10.36 FPS\n",
      "Time taken for model inference is: 25.288275718688965\n",
      "model runs at 10.36 FPS\n",
      "Time taken for model inference is: 25.371958017349243\n",
      "model runs at 10.37 FPS\n",
      "Time taken for model inference is: 25.452372074127197\n",
      "model runs at 10.37 FPS\n",
      "Time taken for model inference is: 25.537551641464233\n",
      "model runs at 10.38 FPS\n",
      "Time taken for model inference is: 25.63309097290039\n",
      "model runs at 10.38 FPS\n",
      "Time taken for model inference is: 25.71002769470215\n",
      "model runs at 10.39 FPS\n",
      "Time taken for model inference is: 25.794906854629517\n",
      "model runs at 10.39 FPS\n",
      "Time taken for model inference is: 25.903752326965332\n",
      "model runs at 10.38 FPS\n",
      "Time taken for model inference is: 25.984002828598022\n",
      "model runs at 10.39 FPS\n",
      "Time taken for model inference is: 26.06818723678589\n",
      "model runs at 10.4 FPS\n",
      "Time taken for model inference is: 26.161937952041626\n",
      "model runs at 10.4 FPS\n",
      "Time taken for model inference is: 26.240198373794556\n",
      "model runs at 10.4 FPS\n",
      "Time taken for model inference is: 26.319726705551147\n",
      "model runs at 10.41 FPS\n",
      "Time taken for model inference is: 26.40232229232788\n",
      "model runs at 10.42 FPS\n",
      "Time taken for model inference is: 26.480552673339844\n",
      "model runs at 10.42 FPS\n",
      "Time taken for model inference is: 26.573615074157715\n",
      "model runs at 10.42 FPS\n",
      "Time taken for model inference is: 26.65955090522766\n",
      "model runs at 10.43 FPS\n",
      "Time taken for model inference is: 26.738998651504517\n",
      "model runs at 10.43 FPS\n",
      "Time taken for model inference is: 26.818830251693726\n",
      "model runs at 10.44 FPS\n",
      "Time taken for model inference is: 26.903306245803833\n",
      "model runs at 10.44 FPS\n",
      "Time taken for model inference is: 26.987040758132935\n",
      "model runs at 10.45 FPS\n",
      "Time taken for model inference is: 27.073997259140015\n",
      "model runs at 10.45 FPS\n",
      "Time taken for model inference is: 27.163772344589233\n",
      "model runs at 10.46 FPS\n",
      "Time taken for model inference is: 27.24063205718994\n",
      "model runs at 10.46 FPS\n",
      "Time taken for model inference is: 27.33435559272766\n",
      "model runs at 10.46 FPS\n",
      "Time taken for model inference is: 27.429771900177002\n",
      "model runs at 10.46 FPS\n",
      "Time taken for model inference is: 27.503907203674316\n",
      "model runs at 10.47 FPS\n",
      "Time taken for model inference is: 27.595433235168457\n",
      "model runs at 10.47 FPS\n",
      "Time taken for model inference is: 27.685009956359863\n",
      "model runs at 10.47 FPS\n",
      "Time taken for model inference is: 27.764090061187744\n",
      "model runs at 10.48 FPS\n",
      "Time taken for model inference is: 27.85488986968994\n",
      "model runs at 10.48 FPS\n",
      "Time taken for model inference is: 27.952470541000366\n",
      "model runs at 10.48 FPS\n",
      "Time taken for model inference is: 28.037484645843506\n",
      "model runs at 10.49 FPS\n",
      "Time taken for model inference is: 28.12289547920227\n",
      "model runs at 10.49 FPS\n",
      "Time taken for model inference is: 28.224416255950928\n",
      "model runs at 10.49 FPS\n",
      "Time taken for model inference is: 28.305938959121704\n",
      "model runs at 10.49 FPS\n",
      "Time taken for model inference is: 28.38475251197815\n",
      "model runs at 10.5 FPS\n",
      "Time taken for model inference is: 28.468400716781616\n",
      "model runs at 10.5 FPS\n",
      "Time taken for model inference is: 28.553669691085815\n",
      "model runs at 10.51 FPS\n",
      "Time taken for model inference is: 28.637428998947144\n",
      "model runs at 10.51 FPS\n",
      "Time taken for model inference is: 28.73288130760193\n",
      "model runs at 10.51 FPS\n",
      "Time taken for model inference is: 28.82453751564026\n",
      "model runs at 10.51 FPS\n",
      "Time taken for model inference is: 28.90460228919983\n",
      "model runs at 10.52 FPS\n",
      "Time taken for model inference is: 28.9950008392334\n",
      "model runs at 10.52 FPS\n",
      "Time taken for model inference is: 29.073355436325073\n",
      "model runs at 10.53 FPS\n",
      "Time taken for model inference is: 29.159482955932617\n",
      "model runs at 10.53 FPS\n",
      "Time taken for model inference is: 29.245315551757812\n",
      "model runs at 10.53 FPS\n",
      "Time taken for model inference is: 29.322109937667847\n",
      "model runs at 10.54 FPS\n",
      "Time taken for model inference is: 29.405041694641113\n",
      "model runs at 10.54 FPS\n",
      "Time taken for model inference is: 29.49821662902832\n",
      "model runs at 10.54 FPS\n",
      "Time taken for model inference is: 29.59515404701233\n",
      "model runs at 10.54 FPS\n",
      "Time taken for model inference is: 29.67808437347412\n",
      "model runs at 10.55 FPS\n",
      "Time taken for model inference is: 29.764523029327393\n",
      "model runs at 10.55 FPS\n",
      "Time taken for model inference is: 29.864196062088013\n",
      "model runs at 10.55 FPS\n",
      "Time taken for model inference is: 29.94119906425476\n",
      "model runs at 10.55 FPS\n",
      "Time taken for model inference is: 30.039509534835815\n",
      "model runs at 10.55 FPS\n",
      "Time taken for model inference is: 30.12574577331543\n",
      "model runs at 10.56 FPS\n",
      "Time taken for model inference is: 30.215969800949097\n",
      "model runs at 10.56 FPS\n",
      "Time taken for model inference is: 30.30690908432007\n",
      "model runs at 10.56 FPS\n",
      "Time taken for model inference is: 30.390301942825317\n",
      "model runs at 10.56 FPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for model inference is: 30.47410297393799\n",
      "model runs at 10.57 FPS\n",
      "Time taken for model inference is: 30.567835569381714\n",
      "model runs at 10.57 FPS\n",
      "Time taken for model inference is: 30.649410486221313\n",
      "model runs at 10.57 FPS\n",
      "Time taken for model inference is: 30.7447726726532\n",
      "model runs at 10.57 FPS\n",
      "Time taken for model inference is: 30.832377195358276\n",
      "model runs at 10.57 FPS\n",
      "Time taken for model inference is: 30.93341588973999\n",
      "model runs at 10.57 FPS\n",
      "Time taken for model inference is: 31.032483339309692\n",
      "model runs at 10.57 FPS\n",
      "Time taken for model inference is: 31.12336540222168\n",
      "model runs at 10.57 FPS\n",
      "Time taken for model inference is: 31.207484006881714\n",
      "model runs at 10.57 FPS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork,IECore\n",
    "from openvino.inference_engine import IEPlugin\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Queue:\n",
    "    '''\n",
    "    Class for dealing with queues\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.queues=[]\n",
    "\n",
    "    def add_queue(self, points):\n",
    "        self.queues.append(points)\n",
    "\n",
    "    def get_queues(self, image):\n",
    "        for q in self.queues:\n",
    "            x_min, y_min, x_max, y_max=q\n",
    "            frame=image[y_min:y_max, x_min:x_max]\n",
    "            yield frame\n",
    "    \n",
    "    def check_coords(self, coords):\n",
    "        d={k+1:0 for k in range(len(self.queues))}\n",
    "        for coord in coords:\n",
    "            for i, q in enumerate(self.queues):\n",
    "                if coord[0]>q[0] and coord[2]<q[2]:\n",
    "                    d[i+1]+=1\n",
    "        return d\n",
    "\n",
    "class PersonDetect:\n",
    "    def __init__(self):\n",
    "        self.plugin = None\n",
    "        self.network = None\n",
    "        self.mod_bin = None\n",
    "        self.mod_xml = None\n",
    "        self.exec_network = None\n",
    "        self.input_blob = None\n",
    "        self.output_blob = None\n",
    "        self.net_input_shape = None\n",
    "        self.frame = None\n",
    "\n",
    "\n",
    "#Loading the model\n",
    "    def load_model(self,model,device):\n",
    "        self.mod_bin = model+'.bin'\n",
    "        self.mod_xml = model+'.xml'\n",
    "        self.plugin = IECore()\n",
    "        self.network = IENetwork(model=self.mod_xml, weights=self.mod_bin)\n",
    "        self.exec_network = self.plugin.load_network(self.network,device_name=device)\n",
    "        #raise NotImplementedError\n",
    "\n",
    "    def inp_out_blob(self):\n",
    "        self.input_blob = next(iter(self.network.inputs))\n",
    "        self.output_blob = next(iter(self.network.outputs))\n",
    "        self.net_input_shape=self.network.inputs[self.input_blob].shape\n",
    "        return(self.net_input_shape)\n",
    "\n",
    "    def preprocess_input(self, image):\n",
    "        self.x=self.net_input_shape[3]\n",
    "        self.y=self.net_input_shape[2]\n",
    "        self.Y,self.X,_ = np.shape(image)\n",
    "        self.frame_resized = cv2.resize(image, (self.net_input_shape[3], self.net_input_shape[2]))\n",
    "        self.frame = self.frame_resized.transpose((2,0,1))\n",
    "        self.frame = self.frame.reshape(1, *self.frame.shape)\n",
    "        return(self.frame,self.frame_resized)\n",
    "\n",
    "        \n",
    "    def predict(self, image):\n",
    "        self.exec_network.start_async(request_id=0, inputs={self.input_blob: image})\n",
    "        while True:\n",
    "            status = self.exec_network.requests[0].wait(-1)               \n",
    "            if status == 0:\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "        return(self)\n",
    "\n",
    " \n",
    "    def wait(self):\n",
    "        status = self.exec_network.requests[0].wait(-1)\n",
    "        return status\n",
    "\n",
    "    def get_output(self):\n",
    "        return self.exec_network.requests[0].outputs[self.output_blob]\n",
    "\n",
    "    def preprocess_output(self,result,thresh):\n",
    "        for i in range(len(result[0][0])):\n",
    "            if result[0][0][i][2]>thresh:\n",
    "                #print('entered')\n",
    "                x1,y1,x2,y2 = result[0][0][i][3],result[0][0][i][4],result[0][0][i][5],result[0][0][i][6]\n",
    "                \n",
    "                self.x1 = x1*self.net_input_shape[3]*(self.X/self.x)\n",
    "                self.y1 = y1*self.net_input_shape[2]*(self.Y/self.y)\n",
    "                self.x2 = x2*self.net_input_shape[3]*(self.X/self.x)\n",
    "                self.y2 = y2*self.net_input_shape[2]*(self.Y/self.y)\n",
    "                \n",
    "                yield(int(self.x1),int(self.y1),int(self.x2),int(self.y2))\n",
    "            else:\n",
    "                yield(0,0,0,0)\n",
    "\n",
    "\n",
    "#def main(args)\n",
    "#extensions=args.extensions\n",
    "model='./intel/person-detection-retail-0013/FP16/person-detection-retail-0013'\n",
    "device='CPU'\n",
    "#visualise=args.visualise\n",
    "queue_param = 'transportation'\n",
    "max_people = 4\n",
    "visualize = True\n",
    "video_file='./resources/transportation.mp4'\n",
    "thresh = 0.8\n",
    "\n",
    "start=time.time()\n",
    "pd=PersonDetect()\n",
    "pd.load_model(model,device)\n",
    "mod_inp_shape = pd.inp_out_blob()\n",
    "\n",
    "print(f\"Time taken to load the model is: {time.time()-start}\")\n",
    "\n",
    "queue=Queue()\n",
    "#Queue Parameters\n",
    "if queue_param == 'retail':\n",
    "   # For retail\n",
    "    queue.add_queue([620, 1, 915, 562])\n",
    "    queue.add_queue([1000, 1, 1264, 461])\n",
    "\n",
    "if queue_param == 'manufacturing':\n",
    "   # For manufacturing\n",
    "    queue.add_queue([15, 180, 730, 780])\n",
    "    queue.add_queue([921, 144, 1424, 704])\n",
    "    \n",
    "if queue_param == 'transportation':\n",
    "   # For transportation\n",
    "    queue.add_queue([150, 0, 1150, 794])\n",
    "    queue.add_queue([1151, 0, 1915, 841])\n",
    "    \n",
    "\n",
    "cap=cv2.VideoCapture(video_file)\n",
    "width  = cap.get(cv2.CAP_PROP_FRAME_WIDTH)   \n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "vid_write = cv2.VideoWriter(str(queue_param)+'.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10,(int(width),int(height)))\n",
    "#print(video_fps)\n",
    "#print(width,height)\n",
    "count = 0\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame_org=cap.read()\n",
    "\n",
    "    count+=1\n",
    "    if not ret:\n",
    "        break\n",
    "    w,h,_ = np.shape(frame_org)\n",
    "    #print(w,h)\n",
    "    #for crop_frame in queue.get_queues(frame):\n",
    "\n",
    "    frame, frame_resized = pd.preprocess_input(frame_org)\n",
    "    pd.predict(frame)\n",
    "    cords=[]\n",
    "    # Get the output of inference\n",
    "    if pd.wait() == 0:\n",
    "\n",
    "        result = pd.get_output()\n",
    "        #print(np.shape(result))\n",
    "\n",
    "    for x1,y1,x2,y2 in pd.preprocess_output(result,thresh):\n",
    "        cv2.rectangle(frame_org,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "        cords.append([x1,y1,x2,y2])\n",
    "        #ppl=pd.count_person(result)\n",
    "        #print('Number of people in Queue_'+str(count2)+' is {}'.format(ppl))\n",
    "    #print(np.shape(frame_org))\n",
    "    d = queue.check_coords(cords)\n",
    "    stn_1 = 'No of person in Queue one :'\n",
    "    stn_2 = 'No of person in Queue two :'\n",
    "    cv2.putText(frame_org,stn_1+str(d[1]),(5,100),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3,cv2.LINE_AA)\n",
    "    cv2.putText(frame_org,stn_2+str(d[2]),(5,135),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3,cv2.LINE_AA)\n",
    "\n",
    "    mx_q1 = 'Too many persons in Queue one, move to other queue'\n",
    "    mx_q2 = 'Too many persons in Queue two, move to other queue'    \n",
    "    if d[1] > max_people:\n",
    "        cv2.putText(frame_org,mx_q1,(5,700),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),2,cv2.LINE_AA)\n",
    "    if d[2] > max_people:\n",
    "        cv2.putText(frame_org,mx_q2,(5,725),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),2,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    #videowriter = cv2.VideoWriter('Haar.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (500,550))\n",
    "\n",
    "    if visualize:\n",
    "        cv2.imshow('output',frame_org)\n",
    "        vid_write.write(frame_org)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(stn_1+str(d[1]))\n",
    "        print(stn_2+str(d[2]))\n",
    "\n",
    "    print(f\"Time taken for model inference is: {time.time()-start}\")\n",
    "    print('model runs at {} FPS'.format(round(count/(time.time()-start),2)))\n",
    "    \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "vid_write.release()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.shape(frame_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(frame_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in check([1,9,8,6,4,3,1]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
